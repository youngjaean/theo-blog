---
{"dg-publish":true,"permalink":"/1-paper/110-vision/114-panoptic-deep-lab/","title":" Panoptic Deep lab","tags":["summary","paper","segmetation"]}
---

# Panoptic-DeepLab: Bottom-Up Panoptic Segmentation의 간단하고 강력한 기준

## 1. 배경

- 기존의 top-down 방식의 panoptic segmentation 모델들은 복잡하고 느린 경
- Bottom-up 접근법은 간단하고 빠르지만 성능이 저하

## 2. 주요 아이디어

Panoptic-DeepLab은 다음과 같은 특징을 가진 bottom-up 방식의 panoptic segmentation 모델:

1. 간단한 구조: 세 가지 loss 함수만 사용
2. 강력한 성능: 최신 top-down 방식과 견줄만한 결과
3. 빠른 속도: 거의 실시간 추론 가능

## 3. 모델 구조
![Pasted image 20240821105021.png](/img/user/0.%EC%A7%80%EC%8B%9D%EC%B0%BD%EA%B3%A0/030.%20source/Pasted%20image%2020240821105021.png)
1. 공유 인코더 백본
2. Dual-ASPP (Atrous Spatial Pyramid Pooling) 모듈
3. Dual-decoder 모듈
4. 태스크별 예측 헤드:
   - 시맨틱 세그멘테이션
   - 클래스 무관 인스턴스 세그멘테이션 (중심점 예측 및 오프셋 회귀)

## 4. 주요 수식

인스턴스 세그멘테이션을 위한 픽셀 그룹화:

$\hat{k}_{i,j} = \arg\min_k ||C_k - ((i, j) + O(i, j))||_2$

여기서 $C_k$는 예측된 인스턴스 중심, $O(i,j)$는 픽셀 $(i,j)$의 예측된 오프셋

## 5. 성능

- Cityscapes 테스트 세트: 65.5% PQ, 39.0% AP, 84.2% mIoU (모두 1위)
- Mapillary Vistas 테스트 세트: 42.7% PQ (2018년 챌린지 우승자보다 1.5% 높음)
- COCO 테스트-dev 세트: 41.4% PQ (top-down 방식과 견줄만한 성능)

## 6. 결론
- 커스텀 데이터로 사용해본 결과 Instance segmentation 이 상대적으로 성능이 낮았다. 
- 최근 기술이 아니다보니 모든 테스크를 다 해결하지 못하는 문제가 발생하지만, 초기 panoptic segmentation 의 연구를 이끈 논문이라 생각한다.